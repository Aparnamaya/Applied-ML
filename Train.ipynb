{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jVcHhab9qhjt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load Data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "val_df = pd.read_csv(\"validation.csv\")\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.dropna(subset=[\"message\"], inplace=True)\n",
        "val_df.dropna(subset=[\"message\"], inplace=True)\n",
        "\n",
        "# Vectorize Text\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
        "X_train = vectorizer.fit_transform(train_df[\"message\"].astype(str))\n",
        "X_val = vectorizer.transform(val_df[\"message\"].astype(str))\n",
        "\n",
        "y_train = train_df[\"label\"]\n",
        "y_val = val_df[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train SVM Model (Linear Kernel)\n",
        "svm = SVC(kernel=\"linear\")\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate_model(model, X, y, dataset_name):\n",
        "    y_pred = model.predict(X)\n",
        "    print(f\"Performance on {dataset_name}:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
        "    print(classification_report(y, y_pred))\n",
        "\n",
        "# Evaluate on Train & Validation\n",
        "print(\"SVM Results:\")\n",
        "evaluate_model(svm, X_train, y_train, \"Train\")\n",
        "evaluate_model(svm, X_val, y_val, \"Validation\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqoctScTrJZw",
        "outputId": "869d3dbe-eaa9-4c61-ca41-ef10cf3e86e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Results:\n",
            "Performance on Train:\n",
            "Accuracy: 0.9959605026929982\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3858\n",
            "           1       1.00      0.97      0.98       598\n",
            "\n",
            "    accuracy                           1.00      4456\n",
            "   macro avg       1.00      0.99      0.99      4456\n",
            "weighted avg       1.00      1.00      1.00      4456\n",
            "\n",
            "Performance on Validation:\n",
            "Accuracy: 0.9802513464991023\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       483\n",
            "           1       1.00      0.85      0.92        74\n",
            "\n",
            "    accuracy                           0.98       557\n",
            "   macro avg       0.99      0.93      0.95       557\n",
            "weighted avg       0.98      0.98      0.98       557\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train Logistic Regression Model\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate_model(model, X, y, dataset_name):\n",
        "    y_pred = model.predict(X)\n",
        "    print(f\"Performance on {dataset_name}:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
        "    print(classification_report(y, y_pred))\n",
        "\n",
        "# Evaluate on Train & Validation\n",
        "print(\"Logistic Regression Results:\")\n",
        "evaluate_model(logreg, X_train, y_train, \"Train\")\n",
        "evaluate_model(logreg, X_val, y_val, \"Validation\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_NQRc6orZe6",
        "outputId": "acf17b4d-2032-4721-db16-e153649f903f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Results:\n",
            "Performance on Train:\n",
            "Accuracy: 0.9717235188509874\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98      3858\n",
            "           1       0.99      0.80      0.88       598\n",
            "\n",
            "    accuracy                           0.97      4456\n",
            "   macro avg       0.98      0.90      0.93      4456\n",
            "weighted avg       0.97      0.97      0.97      4456\n",
            "\n",
            "Performance on Validation:\n",
            "Accuracy: 0.9658886894075404\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       483\n",
            "           1       1.00      0.74      0.85        74\n",
            "\n",
            "    accuracy                           0.97       557\n",
            "   macro avg       0.98      0.87      0.92       557\n",
            "weighted avg       0.97      0.97      0.96       557\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train Naïve Bayes Model\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate_model(model, X, y, dataset_name):\n",
        "    y_pred = model.predict(X)\n",
        "    print(f\"Performance on {dataset_name}:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
        "    print(classification_report(y, y_pred))\n",
        "\n",
        "# Evaluate on Train & Validation\n",
        "print(\"Naïve Bayes Results:\")\n",
        "evaluate_model(nb, X_train, y_train, \"Train\")\n",
        "evaluate_model(nb, X_val, y_val, \"Validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MhYJiGgrhYD",
        "outputId": "fcb95648-9e32-4702-def5-6466e95d4cb8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naïve Bayes Results:\n",
            "Performance on Train:\n",
            "Accuracy: 0.9849640933572711\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      3858\n",
            "           1       1.00      0.89      0.94       598\n",
            "\n",
            "    accuracy                           0.98      4456\n",
            "   macro avg       0.99      0.94      0.97      4456\n",
            "weighted avg       0.99      0.98      0.98      4456\n",
            "\n",
            "Performance on Validation:\n",
            "Accuracy: 0.9694793536804309\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       483\n",
            "           1       1.00      0.77      0.87        74\n",
            "\n",
            "    accuracy                           0.97       557\n",
            "   macro avg       0.98      0.89      0.93       557\n",
            "weighted avg       0.97      0.97      0.97       557\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train Data (Assuming you already have this from the previous steps)\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Handle Missing Values\n",
        "train_df.dropna(subset=[\"message\"], inplace=True)\n",
        "test_df.dropna(subset=[\"message\"], inplace=True)\n",
        "\n",
        "# Vectorize Text\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
        "X_train = vectorizer.fit_transform(train_df[\"message\"].astype(str))\n",
        "X_test = vectorizer.transform(test_df[\"message\"].astype(str))\n",
        "\n",
        "y_train = train_df[\"label\"]\n",
        "y_test = test_df[\"label\"]\n",
        "\n",
        "# Initialize models\n",
        "logreg = LogisticRegression()\n",
        "nb = MultinomialNB()\n",
        "svm = SVC(kernel=\"linear\")\n",
        "\n",
        "# Fit models\n",
        "logreg.fit(X_train, y_train)\n",
        "nb.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Function\n",
        "def evaluate_model(model, X, y, model_name):\n",
        "    y_pred = model.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    report = classification_report(y, y_pred)\n",
        "    return accuracy, report\n",
        "\n",
        "# Evaluate all models on test data\n",
        "models = [logreg, nb, svm]\n",
        "model_names = [\"Logistic Regression\", \"Naïve Bayes\", \"SVM\"]\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "\n",
        "for model, name in zip(models, model_names):\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test, name)\n",
        "    print(f\"{name} Performance on Test Data:\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(report)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Check for the best model\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = model\n",
        "        best_model_name = name\n",
        "\n",
        "print(f\"Best Model: {best_model_name} with Accuracy: {best_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HswmCrTXrprX",
        "outputId": "ca70c2b9-5d9e-45d3-e0a5-2c6a79909690"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Performance on Test Data:\n",
            "Accuracy: 0.9730700179533214\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       482\n",
            "           1       1.00      0.80      0.89        75\n",
            "\n",
            "    accuracy                           0.97       557\n",
            "   macro avg       0.98      0.90      0.94       557\n",
            "weighted avg       0.97      0.97      0.97       557\n",
            "\n",
            "--------------------------------------------------\n",
            "Naïve Bayes Performance on Test Data:\n",
            "Accuracy: 0.9730700179533214\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       482\n",
            "           1       1.00      0.80      0.89        75\n",
            "\n",
            "    accuracy                           0.97       557\n",
            "   macro avg       0.98      0.90      0.94       557\n",
            "weighted avg       0.97      0.97      0.97       557\n",
            "\n",
            "--------------------------------------------------\n",
            "SVM Performance on Test Data:\n",
            "Accuracy: 0.9838420107719928\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       482\n",
            "           1       0.99      0.89      0.94        75\n",
            "\n",
            "    accuracy                           0.98       557\n",
            "   macro avg       0.98      0.95      0.96       557\n",
            "weighted avg       0.98      0.98      0.98       557\n",
            "\n",
            "--------------------------------------------------\n",
            "Best Model: SVM with Accuracy: 0.9838420107719928\n"
          ]
        }
      ]
    }
  ]
}